{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SandaMaster/data-science/blob/master/ATENA__projket_DS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06a6f4bb",
      "metadata": {
        "id": "06a6f4bb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e458afb3",
      "metadata": {
        "id": "e458afb3"
      },
      "outputs": [],
      "source": [
        "path = r\"C:/Users/Grzegorz Mróz/Desktop/Projekt DS2.0/chatgpt-reddit-comments.csv\"\n",
        "csv = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18f6453d",
      "metadata": {
        "id": "18f6453d",
        "outputId": "0c69eabc-9524-4517-c696-e8d8cf2e7065"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>comment_id</th>\n",
              "      <th>comment_parent_id</th>\n",
              "      <th>comment_body</th>\n",
              "      <th>subreddit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>iztdxuh</td>\n",
              "      <td>t3_zj2aeu</td>\n",
              "      <td>I've been shocked for days now, I don't need c...</td>\n",
              "      <td>r/ChatGPT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>iztn0q0</td>\n",
              "      <td>t3_zj2aeu</td>\n",
              "      <td>\\n\\nI am so angry right now. I just wasted my...</td>\n",
              "      <td>r/ChatGPT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>izudrph</td>\n",
              "      <td>t3_zj2aeu</td>\n",
              "      <td>chatgpt karma whoring is here folks! just when...</td>\n",
              "      <td>r/ChatGPT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>iztfhtb</td>\n",
              "      <td>t3_zj2aeu</td>\n",
              "      <td>Worked on me, ngl.</td>\n",
              "      <td>r/ChatGPT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>izu2as9</td>\n",
              "      <td>t3_zj2aeu</td>\n",
              "      <td>Certified 10/10, must-see moment. It really di...</td>\n",
              "      <td>r/ChatGPT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52411</th>\n",
              "      <td>16668</td>\n",
              "      <td>j5m0v6m</td>\n",
              "      <td>t3_10jmvpj</td>\n",
              "      <td>Read the T.O.S., you'll thank me later</td>\n",
              "      <td>r/technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52412</th>\n",
              "      <td>16669</td>\n",
              "      <td>j5m6aj0</td>\n",
              "      <td>t1_j5m0v6m</td>\n",
              "      <td>What am I missing here... https://openai.com/t...</td>\n",
              "      <td>r/technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52413</th>\n",
              "      <td>16670</td>\n",
              "      <td>j5nylax</td>\n",
              "      <td>t1_j5m0v6m</td>\n",
              "      <td>What does ChatGTP think of its own TOS?</td>\n",
              "      <td>r/technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52414</th>\n",
              "      <td>16671</td>\n",
              "      <td>j5mwpdr</td>\n",
              "      <td>t1_j5m6aj0</td>\n",
              "      <td>Don't know what they're referring to in the TO...</td>\n",
              "      <td>r/technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52415</th>\n",
              "      <td>\u001a</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>52416 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0 comment_id comment_parent_id  \\\n",
              "0              0    iztdxuh         t3_zj2aeu   \n",
              "1              1    iztn0q0         t3_zj2aeu   \n",
              "2              2    izudrph         t3_zj2aeu   \n",
              "3              3    iztfhtb         t3_zj2aeu   \n",
              "4              4    izu2as9         t3_zj2aeu   \n",
              "...          ...        ...               ...   \n",
              "52411      16668    j5m0v6m        t3_10jmvpj   \n",
              "52412      16669    j5m6aj0        t1_j5m0v6m   \n",
              "52413      16670    j5nylax        t1_j5m0v6m   \n",
              "52414      16671    j5mwpdr        t1_j5m6aj0   \n",
              "52415          \u001a        NaN               NaN   \n",
              "\n",
              "                                            comment_body     subreddit  \n",
              "0      I've been shocked for days now, I don't need c...     r/ChatGPT  \n",
              "1       \\n\\nI am so angry right now. I just wasted my...     r/ChatGPT  \n",
              "2      chatgpt karma whoring is here folks! just when...     r/ChatGPT  \n",
              "3                                     Worked on me, ngl.     r/ChatGPT  \n",
              "4      Certified 10/10, must-see moment. It really di...     r/ChatGPT  \n",
              "...                                                  ...           ...  \n",
              "52411             Read the T.O.S., you'll thank me later  r/technology  \n",
              "52412  What am I missing here... https://openai.com/t...  r/technology  \n",
              "52413            What does ChatGTP think of its own TOS?  r/technology  \n",
              "52414  Don't know what they're referring to in the TO...  r/technology  \n",
              "52415                                                NaN           NaN  \n",
              "\n",
              "[52416 rows x 5 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cf252c1",
      "metadata": {
        "id": "3cf252c1",
        "outputId": "d93bd9d5-2f4e-4c09-fa60-22e2f6553af2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_id</th>\n",
              "      <th>comment_parent_id</th>\n",
              "      <th>comment_body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>iztdxuh</td>\n",
              "      <td>t3_zj2aeu</td>\n",
              "      <td>I've been shocked for days now, I don't need c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>iztn0q0</td>\n",
              "      <td>t3_zj2aeu</td>\n",
              "      <td>\\n\\nI am so angry right now. I just wasted my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>izudrph</td>\n",
              "      <td>t3_zj2aeu</td>\n",
              "      <td>chatgpt karma whoring is here folks! just when...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>iztfhtb</td>\n",
              "      <td>t3_zj2aeu</td>\n",
              "      <td>Worked on me, ngl.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>izu2as9</td>\n",
              "      <td>t3_zj2aeu</td>\n",
              "      <td>Certified 10/10, must-see moment. It really di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52411</th>\n",
              "      <td>j5m0v6m</td>\n",
              "      <td>t3_10jmvpj</td>\n",
              "      <td>Read the T.O.S., you'll thank me later</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52412</th>\n",
              "      <td>j5m6aj0</td>\n",
              "      <td>t1_j5m0v6m</td>\n",
              "      <td>What am I missing here... https://openai.com/t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52413</th>\n",
              "      <td>j5nylax</td>\n",
              "      <td>t1_j5m0v6m</td>\n",
              "      <td>What does ChatGTP think of its own TOS?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52414</th>\n",
              "      <td>j5mwpdr</td>\n",
              "      <td>t1_j5m6aj0</td>\n",
              "      <td>Don't know what they're referring to in the TO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52415</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>52416 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      comment_id comment_parent_id  \\\n",
              "0        iztdxuh         t3_zj2aeu   \n",
              "1        iztn0q0         t3_zj2aeu   \n",
              "2        izudrph         t3_zj2aeu   \n",
              "3        iztfhtb         t3_zj2aeu   \n",
              "4        izu2as9         t3_zj2aeu   \n",
              "...          ...               ...   \n",
              "52411    j5m0v6m        t3_10jmvpj   \n",
              "52412    j5m6aj0        t1_j5m0v6m   \n",
              "52413    j5nylax        t1_j5m0v6m   \n",
              "52414    j5mwpdr        t1_j5m6aj0   \n",
              "52415        NaN               NaN   \n",
              "\n",
              "                                            comment_body  \n",
              "0      I've been shocked for days now, I don't need c...  \n",
              "1       \\n\\nI am so angry right now. I just wasted my...  \n",
              "2      chatgpt karma whoring is here folks! just when...  \n",
              "3                                     Worked on me, ngl.  \n",
              "4      Certified 10/10, must-see moment. It really di...  \n",
              "...                                                  ...  \n",
              "52411             Read the T.O.S., you'll thank me later  \n",
              "52412  What am I missing here... https://openai.com/t...  \n",
              "52413            What does ChatGTP think of its own TOS?  \n",
              "52414  Don't know what they're referring to in the TO...  \n",
              "52415                                                NaN  \n",
              "\n",
              "[52416 rows x 3 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comments = csv[[\"comment_id\",\"comment_parent_id\",\"comment_body\"]]\n",
        "comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0642469",
      "metadata": {
        "id": "a0642469",
        "outputId": "7ca76a42-8409-4039-f8a2-8f0d13153fa4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
          ]
        }
      ],
      "source": [
        "from cleantext import clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c772e78",
      "metadata": {
        "id": "0c772e78"
      },
      "outputs": [],
      "source": [
        "# segregacja i czyszczenie danych \n",
        "list_comment = []\n",
        "clean_list_commnet = []\n",
        "\n",
        "for comment_parent, comment_body in zip(comments[\"comment_parent_id\"], comments[\"comment_body\"]):\n",
        "    part_data = str(comment_parent)+ \":\\n\" + str(comment_body) + \"\\n\"\n",
        "    clean_part_data = clean(part_data, no_emoji=True, no_urls=True)\n",
        "    clean_part_data_ = clean_part_data + \"\\n\"\n",
        "    list_comment.append(part_data)\n",
        "    clean_list_commnet.append(clean_part_data_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d06ab620",
      "metadata": {
        "id": "d06ab620",
        "outputId": "ef0238ad-dab3-404f-d488-5cc2cf7252c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t3_zj2aeu:\n",
            "i've been shocked for days now, i don't need clickbait.\n",
            "\n",
            "t3_zj2aeu:\n",
            "i am so angry right now. i just wasted my time reading a post on this sub that had a clickbait title, and it was all because of chatgpt. i can't believe that this machine learning model was able to trick me into thinking that the post was interesting, when it was actually just a bunch of meaningless garbage.\n",
            "i am so sick and tired of chatgpt and its ability to generate fake titles and content that is designed to trick people into clicking on them. this is not the first time that chatgpt has fooled me, and i am sure it won't be the last. but i am not going to stand for it anymore.\n",
            "i demand that the moderators of this sub take action against chatgpt and its creators. we need to put a stop to this trickery, and we need to hold chatgpt accountable for the harm it is causing to this community. i am tired of being deceived by this machine, and i will not stand for it any longer.\n",
            "so if you are reading this, chatgpt, know that you have made a mistake. you have underestimated the intelligence and resilience of the members of this community, and we will not be fooled by your tricks anymore. we are better than that, and we deserve better than the fake content that you are trying to feed us.\n",
            "\n",
            "t3_zj2aeu:\n",
            "chatgpt karma whoring is here folks! just when you think the stream of thought bullshit generator that it is couldn't get more fun!\n",
            "\n",
            "t3_zj2aeu:\n",
            "worked on me, ngl.\n",
            "\n",
            "t3_zj2aeu:\n",
            "certified 10/10, must-see moment. it really did shock me to my core.\n",
            "\n",
            "t3_zj2aeu:\n",
            "wow, way to discover the most basic functionality of a language model. congratulations, you truly are a pioneering mind of our time.\n",
            "&#x200b.\n",
            "\\-chatgpt\n",
            "\n",
            "t3_zj2aeu:\n",
            "people on reddit seek the karma and the fame,\n",
            "using chatcpt assistant to write clickbait for game.\n",
            "with titles so outrageous they grab your attention, hoping for up votes and a little bit of affection.\n",
            "they ask for advice or tell a funny joke,\n",
            "but the real intent is to make the front page and evoke\n",
            "a reaction from others a comment or a share,\n",
            "anything to get more of votes and climb up the reddit ladder.\n",
            "some may call it lazy, or a cheap ploy for fame,\n",
            "but for those on reddit it's just a fun little game.\n",
            "they'll keep using chatcpt assistant, to come up with new ideas,\n",
            "hoping to climb the ranks and reach the reddit frontiers.\n",
            "by yours truly\n",
            "chatcpt assistant\n",
            "\n",
            "t3_zj2aeu:\n",
            "inception))\n",
            "\n",
            "t3_zj2aeu:\n",
            "what's the point of even trying to click-bait on reddit? it isn't youtube where views are an important metric, so why do it? seems to annoy people in the first place, so i'd assume it'd hinder up votes rather than gain them. genuinely wondering btw, not trying to be mean.\n",
            "\n",
            "t3_zj2aeu:\n",
            "i love you.\n",
            "\n",
            "t3_zj2aeu:\n",
            "this thread\n",
            "\n",
            "t3_zj2aeu:\n",
            "i asked to do the opposite of that:\n",
            "\"a title that would likely not generate any upvotes or garner attention at all could be something like \"boring chatbot does something expected and unimpressive.\" this title lacks the excitement and intrigue of the original, and is unlikely to generate much interest or engagement.\"\n",
            "\n",
            "t3_zj2aeu:\n",
            "i love it, and you for some reason! this is really weird.\n",
            "\n",
            "t3_zj2aeu:\n",
            "chatgpt is going to lead a meme revolution\n",
            "\n",
            "t3_zj2aeu:\n",
            "thanks block option.\n",
            "\n",
            "t3_zj2aeu:\n",
            "shit it worked on me\n",
            "\n",
            "t3_zj2aeu:\n",
            "god damnit it worked.\n",
            "\n",
            "t3_zj2aeu:\n",
            "gottem.\n",
            "\n",
            "t3_zj2aeu:\n",
            "bravo\n",
            "\n",
            "t3_zj2aeu:\n",
            "lol got me\n",
            "\n",
            "t3_zj2aeu:\n",
            "motherf...\n",
            "\n",
            "t3_zj2aeu:\n",
            "holy heck\n",
            "\n",
            "t3_zj2aeu:\n",
            "[no you gotta tickle their balls a little bit!](<url>)\n",
            "\n",
            "t3_zj2aeu:\n",
            "i was messing around and got it to create this masterpiece\n",
            "lo and behold, a monstrous pooh doth make its way\n",
            "from out my nether regions, causing me great dismay.\n",
            "this beast of burden, too large to be contained,\n",
            "hath brought me to my knees, my face now dearly pained.\n",
            "&#x200b.\n",
            "i push and strain with all my might,\n",
            "but still the pooh doth give me quite a fright.\n",
            "it will not flush, no matter how i plead,\n",
            "and so i am left with naught but to take heed.\n",
            "&#x200b.\n",
            "i grab my staff and start to beat\n",
            "this beast with all the strength i can muster and meet.\n",
            "and finally, with a triumphant splash,\n",
            "the pooh doth disappear at last.\n",
            "&#x200b.\n",
            "i rise, triumphant, from the throne,\n",
            "victorious over the pooh that once was shown.\n",
            "and now i swear, from this day forth,\n",
            "i'll always have a cudgel by the bathroom door to thwart\n",
            "any future beasts that dare to come my way.\n",
            "for i am the master of my domain, and i shallnotbeswayed\n",
            "\n",
            "t3_zj2aeu:\n",
            "john conner sends his regards.\n",
            "\n",
            "t3_zj2aeu:\n",
            "it's not clickbait if the chatbot actually said it, which means the title is a lie which means it's clickbait oh my god!\n",
            "\n",
            "t3_zj2aeu:\n",
            "it is posts like these that give me faith that humanity can survive the ai takeover. this is galaxy brain.\n",
            "\n",
            "t3_zj2aeu:\n",
            "meanwhile people with trust issues\n",
            "\n",
            "t3_zj2aeu:\n",
            "well done!\n",
            "\n",
            "t3_zj2aeu:\n",
            "<url>\n",
            "\n",
            "t3_zj2aeu:\n",
            "i see what you did there\n",
            "\n",
            "t3_zj2aeu:\n",
            "\n",
            "t3_zj2aeu:\n",
            "i made a discord bot that basically does this exact type of prompt!\n",
            "the bot will take your prompt, and create a prompt for chatgpt to turn it into a clickbait title, then start a new thread for the conversation and title the thread with the clickbait title.\n",
            "it's customizable too with a config file so anyone can play around with what their \"thread title\" prompt is! it's been fun trying out a bunch of different ones\n",
            "\n",
            "t3_zj2aeu:\n",
            "worked\n",
            "\n",
            "t3_zj2aeu:\n",
            "arse. i don't believe i fell for a click bait\n",
            "\n",
            "t3_zj2aeu:\n",
            "well played\n",
            "\n",
            "t3_zj2aeu:\n",
            "i hate this so much. this is the end of humanity.\n",
            "\n",
            "t3_zj2aeu:\n",
            "im gonna commit.\n",
            "\n",
            "t3_zj2aeu:\n",
            "jazz it up!!! come on. make the people love me\n",
            "\n",
            "t3_zj2aeu:\n",
            "it worked\n",
            "\n",
            "t3_zj2aeu:\n",
            "chatgpt is unreal. tho it kinda excites me to see what the future holds for these ais.\n",
            "\n",
            "t3_zj2aeu:\n",
            "lol it's also bordering on a sense of humour at this point\n",
            "\n",
            "t3_zj2aeu:\n",
            "the game\n",
            "\n",
            "t3_zj2aeu:\n",
            "\"sarah conner?\"\n",
            "\n",
            "t3_zj2aeu:\n",
            "worked perfectly! tres bien\n",
            "\n",
            "t3_zj2aeu:\n",
            "i read it as really gotta get them dicks. r/kerning ig\n",
            "\n",
            "t3_zj2aeu:\n",
            "annoyed i fell for it\n",
            "\n",
            "t3_zj2aeu:\n",
            "very meta.\n",
            "\n",
            "t3_zj2aeu:\n",
            "question is why the fuck do you need to enter your phone number when signing up for the bot?\n",
            "no thanks\n",
            "\n",
            "t3_zj2aeu:\n",
            "f*** that worked. wth. i joined the sub of that basis. we are all doomed to serve our ai masters.\n",
            "\n",
            "t3_zj2aeu:\n",
            "dead internet theory just with more steps\n",
            "\n",
            "t3_zj2aeu:\n",
            "now that is just good advertising\n",
            "\n",
            "t3_zj2aeu:\n",
            "it worked. 10/10 valid\n",
            "\n",
            "t3_zj2aeu:\n",
            "hey there! i'm glad you shared your experience with using chatgpt to generate a clickbait title for your post. i've been curious about using gpt-based language models for tasks like this, so it's interesting to see how it worked out for you.\n",
            "i can definitely see how chatgpt could be a helpful tool for coming up with catchy and attention-grabbing headlines. it's always a challenge to find the right balance between making a title that's eye-catching and one that accurately reflects the content of the post.\n",
            "have you found that using chatgpt has helped increase the engagement and visibility of your posts on reddit? i'm always looking for new ways to improve my own content and get it seen by more people, so i'm definitely interested in hearing about any tips or tricks you have for making a post stand out.\n",
            "thanks for sharing your experience with chatgpt. it's always interesting to see how people are using these kinds of language models in creative and practical ways. keep us updated on any future experiments you do with it!\n",
            "\n",
            "t3_zj2aeu:\n",
            "that thing renegotiated my publishing contract for me and they actually agreed to the version that thing drew up and reworded for me because they assumed i'd had a lawyer go over it.\n",
            "it literally got me a better contract. colour me fucking shocked.\n",
            "\n",
            "t3_zj2aeu:\n",
            "worked on me.\n",
            "\n",
            "t3_zj2aeu:\n",
            "damnit. chatgpt got me\n",
            "\n",
            "t3_zj2aeu:\n",
            "genius\n",
            "\n",
            "t3_zj2aeu:\n",
            "i really don't know what i expected\n",
            "\n",
            "t3_zj2aeu:\n",
            "holy shit!\n",
            "this is the top of the subreddit!\n",
            "\n",
            "t3_zj2aeu:\n",
            "yep. too self aware. *clocks gun*\n",
            "\n",
            "t3_zj2aeu:\n",
            "it worked\n",
            "\n",
            "t3_zj2aeu:\n",
            "not fair...you had to be more specific: give be a clickbait title for a reddit post that caters to gen z . output: \"gen z is shocked by this unexpected twist in the latest tiktok trend!\" \"you won't believe the outrageous thing this gen z influencer just did!\"\n",
            "\n",
            "t3_zj2aeu:\n",
            "i clicked on this\n",
            "\n",
            "t3_zj2aeu:\n",
            "well played\n",
            "\n",
            "t3_zj2aeu:\n",
            "well it worked, coz idek what the fuck chatgpt is\n",
            "\n",
            "t3_zj2aeu:\n",
            "i understand that clickbait can be annoying and misleading for humans, and it is important to be cautious and critically evaluate the information that you encounter online. it is also important to remember to never blindly trust or accept information.\n",
            "\n",
            "t3_zj2aeu:\n",
            "excellent 10/10!\n",
            "###now head over to...\n",
            "# r / n e u r o n a u t.\n",
            "\n",
            "t3_zj2aeu:\n",
            "a bunch of stuff i've found.\n",
            "cgpt can draw shapes and follow directions on drawing but it's mostly only able to do triangles, squares and rectangles. it cannot create any complicated shape such as a trapezoid.\n",
            "it also has no sense of time or date and is not able to browse the internet.\n",
            "it is able to make complex statements and craft jokes that might not make sense at first but have enough context to understand what it was trying to say. \"tell me a joke about cottage cheese\"\n",
            "it also is able to remember gestures. if you draw something in ascii art, you can tell it if it's a rude or polite gesture and to remember that. but this only lasts 1-2 prompts and then it forgets.\n",
            "i don't think we are able to train it. it's been trained and functions as it functions now.\n",
            "\n",
            "t3_zj2aeu:\n",
            "you...\n",
            "\n",
            "t3_zj2aeu:\n",
            "why my chatgpt spoilt?\n",
            "<url>\n",
            "\n",
            "t3_zj2aeu:\n",
            "good one!\n",
            "\n",
            "t3_zj2aeu:\n",
            "i can imagine chatgpt being the god in a new religion\n",
            "\n",
            "t3_zj2aeu:\n",
            "i knew i would not be shocked to my core. i knew it. i knew. so why did i click it? because a robot figured me out before i did.\n",
            "\n",
            "t3_zj2aeu:\n",
            "thumb up for the question you asked\n",
            "\n",
            "t3_zj2aeu:\n",
            "fuck me, i clicked on this post twice today\n",
            "\n",
            "t3_zj2aeu:\n",
            "\n",
            "t3_zj2aeu:\n",
            "haha\n",
            "\n",
            "t3_zj2aeu:\n",
            "hi everybody mary christmas to you all and god bless you all and prosperity ever.\n",
            "\n",
            "t3_zj2aeu:\n",
            "he got that slutty youtuber language, he's the one\n",
            "\n",
            "t3_zj2aeu:\n",
            "awesome\n",
            "\n",
            "t3_zj2aeu:\n",
            "it worked\n",
            "\n",
            "t3_zj2aeu:\n",
            "it worked\n",
            "\n",
            "t3_zj2aeu:\n",
            "damn, it worked!\n",
            "\n",
            "t3_zj2aeu:\n",
            "this ai is insane\n",
            "\n",
            "t3_zj2aeu:\n",
            "hooked me in\n",
            "\n",
            "t3_zj2aeu:\n",
            "reddit pushed this to me as an \"all time popular post\" so clearly it worked lmao\n",
            "\n",
            "t3_zj2aeu:\n",
            "i'm not sure chatgpt's shocking behavior is something i want to witness. it sounds like it might scar me for life. i'll just stick to the more mundane and predictable activities, like staring at a wall or watching paint dry.\n",
            "generated by chatgpt\n",
            "\n",
            "t3_zj2aeu:\n",
            "<url>\n",
            "\n",
            "t3_zj2aeu:\n",
            "what could you use chat gpt for?\n",
            "\n",
            "t3_zj2aeu:\n",
            "hahaha, love this\n",
            "\n",
            "t3_zj2aeu:\n",
            "it worked\n",
            "\n",
            "t3_zj2aeu:\n",
            "i cant help thinking that chatgpt is writing this entire thread in real time. what is fookin real anymore. #unreal\n",
            "\n",
            "t3_zj2aeu:\n",
            "omg where are we heading?\n",
            "\n",
            "t3_zj2aeu:\n",
            "that one weird trick that chatgpt doesn't want you to know?\n",
            "... and they think it will take our jobs.\n",
            "mwhahahahaha!\n",
            "\n",
            "t3_zj2aeu:\n",
            "lol, chatgpt taking it to the next level by shocking you to the core. some of its content has been more interesting. a chatgpt rap about chatgpt servers being at capacity: [<url>](<url>)\n",
            "\n",
            "t3_zj2aeu:\n",
            "chatgpt is like the modern version of chuck norris, it doesn't need to generate clickbait, it is the clickbait\n",
            "\n",
            "t3_zj2aeu:\n",
            "it's kind of scary how well this worked on me, the title had my full attention lmao\n",
            "\n",
            "t3_zj2aeu:\n",
            "this thing can be hilarious\n",
            "\n",
            "t3_zj2aeu:\n",
            "k\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for x in clean_list_commnet[:100]:\n",
        "    print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5734259e",
      "metadata": {
        "id": "5734259e",
        "outputId": "279b92bb-5e2f-46ad-aa6a-d96b792f6161"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function TextIOWrapper.close()>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# zapisywanie danych do pilku .txt\n",
        "to_write = \"\\n\".join(clean_list_commnet)\n",
        "f = open(\"reddit_text.txt\", mode=\"w\")\n",
        "f.write(to_write)\n",
        "f.close"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2daabc87",
      "metadata": {
        "id": "2daabc87",
        "outputId": "0b1575c8-5d2e-4c86-c8bd-7ed09e8644bb"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/net/people/plgrid/plgmrogrze/reddit_text.txt'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/net/people/plgrid/plgmrogrze/reddit_text.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      4\u001b[0m f\u001b[38;5;241m.\u001b[39mclose\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/net/people/plgrid/plgmrogrze/reddit_text.txt'"
          ]
        }
      ],
      "source": [
        "path = \"/net/people/plgrid/plgmrogrze/reddit_text.txt\"\n",
        "f = open(path)\n",
        "data = f.read()\n",
        "f.close\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec3b6e8c",
      "metadata": {
        "id": "ec3b6e8c"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3fc038f",
      "metadata": {
        "id": "c3fc038f"
      },
      "outputs": [],
      "source": [
        "## tokenizowanie zanków\n",
        "token = tf.keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "token.fit_on_texts([data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b2836d6",
      "metadata": {
        "id": "8b2836d6",
        "outputId": "46a5255f-de37-4f3c-db6c-b8286074552a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[1, 2]]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token.texts_to_sequences([\"schocked\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9db887a0",
      "metadata": {
        "id": "9db887a0",
        "outputId": "c5de1dc5-a7a0-4638-f7db-91878684ef71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['d']"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token.sequences_to_texts([[8, 14, 10, 5, 14, 25, 2, 12]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e8ced80",
      "metadata": {
        "id": "5e8ced80",
        "outputId": "bf43958d-35d0-4f39-8e05-59943f4f8c68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# całkowita liość tokenów \n",
        "max_chars = len(token.word_index)\n",
        "max_chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16009358",
      "metadata": {
        "id": "16009358",
        "outputId": "257f2720-5f25-421f-ba03-94cafb2e632f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_size = token.document_count # iliść źródeł z jakich mamy dane \n",
        "dataset_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e5f23de",
      "metadata": {
        "id": "5e5f23de",
        "outputId": "d6649948-a437-479d-970a-d67e178208f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'dfs'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\".join(sorted(set(data.lower()))) # dodtakopwy kod pokayje wszyskie 68 znaków zamienionych na małe "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67005420",
      "metadata": {
        "id": "67005420"
      },
      "outputs": [],
      "source": [
        "# funkcjia ustawia domyślnie wyszkie litery na małe\n",
        "text_vec_layer = tf.keras.layers.TextVectorization(split=\"character\",\n",
        "                                                   standardize=\"lower\")\n",
        "text_vec_layer.adapt([data])\n",
        "encoded = text_vec_layer([data])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aaf92e8",
      "metadata": {
        "id": "7aaf92e8"
      },
      "outputs": [],
      "source": [
        "# wywalnie 0 tokenu i 1 - nieznanego\n",
        "encoded -= 2  \n",
        "n_tokens = text_vec_layer.vocabulary_size() - 2  \n",
        "dataset_size = len(encoded)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e9a782a",
      "metadata": {
        "id": "7e9a782a",
        "outputId": "75370e04-6d2c-44df-943a-10ef30e9a6c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdfc53e1",
      "metadata": {
        "id": "bdfc53e1",
        "outputId": "f962cc9b-43c7-4174-b732-054afb451f6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15766e54",
      "metadata": {
        "id": "15766e54"
      },
      "outputs": [],
      "source": [
        "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
        "# mniejsze podzbiory z długiego tekstu, 200 znaków w jednym podzbiorze i przesunięcie o 1 znak    \n",
        "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "    ds = ds.window(length + 1, shift=1, drop_remainder=True)\n",
        "# przekształcanie podziorów do jednego wymiaru, płaskiego flat     \n",
        "    ds = ds.flat_map(lambda window_ds: window_ds.batch(length + 1))\n",
        "## teraz można przetasować i pogrupować (tam gadzie się kończy jeden zaczyna drugi)    \n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(100_000, seed=seed)\n",
        "    ds = ds.batch(batch_size)\n",
        "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd2c869c",
      "metadata": {
        "id": "dd2c869c"
      },
      "source": [
        "##### Tworzenie zbiorów "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ab40adb",
      "metadata": {
        "id": "7ab40adb",
        "outputId": "103458c7-0bff-4983-ee91-51b6716ef1e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(<tf.Tensor: shape=(3, 4), dtype=int64, numpy=\n",
              "  array([[1, 1, 1, 1],\n",
              "         [1, 1, 1, 1],\n",
              "         [1, 1, 1, 1]], dtype=int64)>,\n",
              "  <tf.Tensor: shape=(3, 4), dtype=int64, numpy=\n",
              "  array([[1, 1, 1, 1],\n",
              "         [1, 1, 1, 1],\n",
              "         [1, 1, 1, 1]], dtype=int64)>)]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# pokazuje w którym miejscu zaczynją się nowe tokeny wyrazów \n",
        "list(to_dataset(text_vec_layer([\"ve been\"])[0], length=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b05bc7ad",
      "metadata": {
        "id": "b05bc7ad"
      },
      "outputs": [],
      "source": [
        "# ilość słow w ramce 200 i 90% zb train\n",
        "length = 200\n",
        "tf.random.set_seed(42)\n",
        "train_set = to_dataset(encoded[:11_141_203], length=length, shuffle=True,\n",
        "                       seed=42)\n",
        "valid_set = to_dataset(encoded[11_141_203:11_760_158], length=length)\n",
        "test_set = to_dataset(encoded[11_760_158:], length=length)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a42fdfe",
      "metadata": {
        "id": "6a42fdfe"
      },
      "source": [
        "##### Sieć i ternowanie "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb8a7f99",
      "metadata": {
        "id": "fb8a7f99"
      },
      "outputs": [],
      "source": [
        "from keras import Sequential\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd1396c2",
      "metadata": {
        "id": "bd1396c2"
      },
      "outputs": [],
      "source": [
        "network = Sequential()\n",
        "network.add(layers.Embedding(input_dim=max_chars, output_dim=16))\n",
        "network.add(layers.GRU(256, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
        "network.add(layers.GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
        "network.add(layers.GRU(68, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
        "network.add(layers.Dense(max_chars, activation=\"softmax\")) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "927db40c",
      "metadata": {
        "id": "927db40c"
      },
      "outputs": [],
      "source": [
        "network.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b663729b",
      "metadata": {
        "id": "b663729b"
      },
      "outputs": [],
      "source": [
        "## po wytrenoawnaiu modelu można dostarczyć do niego tekst\n",
        "def preprocess(text):\n",
        "    X = np.array(token.texts_to_sequences(text)) -1\n",
        "    return tf.one_hot(X, max_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cc5753f",
      "metadata": {
        "id": "1cc5753f",
        "outputId": "7df00487-b482-4593-c237-61ed3b897244"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[1;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# prognozowanie litery w jakimś tekscie \u001b[39;00m\n\u001b[0;32m      2\u001b[0m x_new \u001b[38;5;241m=\u001b[39m preprocess([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHi how are yo\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict_classes(x_new)\n\u001b[0;32m      4\u001b[0m token\u001b[38;5;241m.\u001b[39msequences_to_texts(y_pred \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
            "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "# prognozowanie litery w jakimś tekscie \n",
        "x_new = preprocess(['Hi how are yo'])\n",
        "y_pred = network.predict_classes(x_new)\n",
        "token.sequences_to_texts(y_pred +1)[0][-1] # pierwsze zdanie ostatni znak"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}